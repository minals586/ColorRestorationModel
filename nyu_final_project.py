# -*- coding: utf-8 -*-
"""NYU FINAL PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pPtf6WKb8l7n4xpDDjjcwcd8C58oN4C0

# NYU FINAL PROJECT
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2


from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, Activation
import tensorflow.keras.backend as K
from keras.datasets import cifar10
from keras import regularizers

#splitting the data set into training and test
cifar10 = tf.keras.datasets.cifar10
(training_images, training_labels), (test_images, test_labels) = cifar10.load_data()

#normalizing the data set so scaling is only from 0-1
training_images_scale = training_images/255
test_images_scale = test_images/255

img1 = training_images[723, :, :, :]
plt.imshow(img1)

#function for turning images from rgb to BW
def rgb2gray(rgb): 
    return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])

#first we convert the image to array ***WHY DO WE DO THIS??
gray_train = np.zeros((50000, 32, 32)) 
#create a for loop so that all the images in the data set can run through it and conver to BW
for i in range(0, 50000):
  gray_train[i, :, :] = rgb2gray(training_images_scale[i,:,:,:])
#reshape the images to add a FOURTH DIMESNION  - 1 channel **** WHY DO WE DO THIS??? 
gray_train = gray_train.reshape(50000, 32, 32, 1)
  
gray_test = np.zeros((10000, 32, 32))
for i in range(0, 10000):
  gray_test[i, :, :] = rgb2gray(test_images_scale[i,:,:,:])
  
gray_test = gray_test.reshape(10000, 32, 32, 1)

plt.subplot(1, 2, 1)
plt.imshow(training_images_scale[9, :, :, :])

plt.subplot(1, 2, 2)
plt.imshow(gray_train[9,:,:, 0]) #even though the image is blue and green, this is how the computer sees it as BW, if we want to as humans see the BW, we can add cmap = 'gray'

plt.subplot(1, 2, 3)
plt.imshow(gray_train[9,:,:, 0], cmap = 'gray')

K.clear_session()
#padding is 'same' because we want to maintain the shape of the image throughout the model because we are not trying to 
#alter the size
#the conv layers extract the important features and the upsampling years add back to insert image features 
model = tf.keras.models.Sequential ([
    tf.keras.layers.Conv2D(32, (4,4), activation = 'relu', input_shape = (32, 32, 1), padding = 'same'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (4,4), activation = 'relu', padding = 'same'),
    tf.keras.layers.Conv2D(64, (4,4), activation = 'relu', padding = 'same'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (4,4), activation = 'relu', padding = 'same'),
    tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),
    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding = 'same'),
    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', padding = 'same'),
    tf.keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'),
    tf.keras.layers.Conv2D(3, (4,4), activation = 'sigmoid', padding = 'same')
])

model.summary()

opt = tf.keras.optimizers.Adam(lr = 0.001)
model.compile(optimizer = opt, loss = 'mse', metrics = ['mae'])

hist = model.fit(gray_train, training_images_scale, epochs = 15, batch_size = 32, validation_split=0.1)

yhat = model.predict(gray_test)
mae = np.mean(np.abs(yhat - test_images_scale))
print(mae)
mse = np.mean((yhat - test_images_scale))
print(mse)

index = 80

plt.subplot(1, 3, 1)
plt.imshow(gray_test[index, :, :, 0], cmap = 'gray')

plt.subplot(1, 3, 2)
plt.imshow(yhat[index, :, : , :])

plt.subplot(1, 3, 3)
plt.imshow(test_images_scale[index, :, :, :])

index = 349

plt.subplot(1, 3, 1)
plt.imshow(gray_test[index, :, :, 0], cmap = 'gray')

plt.subplot(1, 3, 2)
plt.imshow(yhat[index, :, : , :])

plt.subplot(1, 3, 3)
plt.imshow(test_images_scale[index, :, :, :])

loss = hist.history['val_loss']
plt.plot(np.arange(1, 16), loss)

#if we want to choose our image and run it through the model
img1 = cv2.imread('landscape.jpg') #reads the image
img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)/255 #converts the image to grayscale

plt.imshow(img1)
print(img1.shape)
plt.figure()
#plt.imshow(img1[1:32,1:32,:])
plt.figure()
img = cv2.resize(img,(32,32)) #resizes the grayscale image
plt.figure()
plt.imshow(img,'gray') #plots the grayscale image

img = img.reshape(1,32,32,1) #reshapes the grayscale image so it can go through the model
yhat1 = model.predict(img) #runs the image through the model
plt.figure()
plt.imshow(yhat1.reshape(32,32,3))

